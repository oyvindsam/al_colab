{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download ala Nils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature vectors using Magellan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from colab.dataset import *\n",
    "from colab.pyem_utils import create_train_test\n",
    "from colab.experiment import do_al_kasai, get_kasai_queries\n",
    "from colab.experiment_utils import *\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform AL - RF - Margin and save like Deepmatcher-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result, dataset, path, filename):\n",
    "    out_dir_idx = os.path.join('out', path)\n",
    "    out_file = os.path.join(out_dir_idx, filename)\n",
    "\n",
    "    if not os.path.exists(out_dir_idx):\n",
    "        try:\n",
    "            os.makedirs(out_dir_idx)\n",
    "        except OSError as e:\n",
    "            print(e.strerror)\n",
    "    \n",
    "    indexes =  pd.DataFrame({\n",
    "        dataset: np.concatenate((result['initial_indexes'], result['indexes'])),\n",
    "    })\n",
    "        \n",
    "    data = pd.DataFrame({\n",
    "        'f1': result['f1'],\n",
    "        'precision': result['precision'],\n",
    "        'recall': result['recall'],\n",
    "        'times': result['times'],\n",
    "    })\n",
    "    \n",
    "    indexes.to_csv(out_file, index=False)\n",
    "    data.to_csv(out_file+'_data', index=True)\n",
    "    \n",
    "    print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_al_all(n_samples=None, all=False, n_initial=8, k=1):\n",
    "    n_queries = 0\n",
    "    \n",
    "    ds = load_datasets(all=all)\n",
    "    # normal AL\n",
    "    for dataset in ds:\n",
    "        print(f'Dataset: {dataset}.')\n",
    "        \n",
    "        d = ds[dataset]\n",
    "        d.load()\n",
    "        \n",
    "        X_train, X_test = create_train_test(d, additional_features=None)\n",
    "        \n",
    "        data = {\n",
    "            'train' : X_train,\n",
    "            'test' : X_test,\n",
    "        }\n",
    "        \n",
    "        n = n_samples if n_samples is not None else len(d.matches_train)\n",
    "        n_queries = get_kasai_queries(n)\n",
    "            \n",
    "        result = do_al_kasai(dataset, data, n_queries)\n",
    "\n",
    "        # write to file\n",
    "        filename = f\"{n_initial}-{n}-{k}\" # initial - queries - k\n",
    "\n",
    "        write_results(result, dataset, d.name, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all datasets in a dictionary\n",
    "def load_datasets(all=False):\n",
    "    data = {}\n",
    "    datasets = dataset_all if all else dataset_small\n",
    "    \n",
    "    for key in datasets:\n",
    "        data[key] = (datasets[key]())\n",
    "    \n",
    "    return data  \n",
    "\n",
    "dataset_all = {\n",
    "    #'deepmatcher_structured_amazon_google': deepmatcher_structured_amazon_google,\n",
    "    #'deepmatcher_structured_beer':deepmatcher_structured_beer,  #fails\n",
    "    #'deepmatcher_structured_dblp_acm': deepmatcher_structured_dblp_acm,\n",
    "    #'deepmatcher_structured_dblp_google_scholar': deepmatcher_structured_dblp_google_scholar,\n",
    "    #'deepmatcher_structured_fodors_zagats': deepmatcher_structured_fodors_zagats,\n",
    "    'deepmatcher_structured_walmart_amazon': deepmatcher_structured_walmart_amazon,  #fails\n",
    "    #'deepmatcher_structured_itunes_amazon': deepmatcher_structured_itunes_amazon,\n",
    "    #'deepmatcher_dirty_dblp_acm': deepmatcher_dirty_dblp_acm,\n",
    "    #'deepmatcher_dirty_dblp_google_scholar': deepmatcher_dirty_dblp_google_scholar, \n",
    "    #'deepmatcher_dirty_walmart_amazon':deepmatcher_dirty_walmart_amazon,   fails\n",
    "    #'deepmatcher_dirty_itunes_amazon':deepmatcher_dirty_itunes_amazon,\n",
    "    #'deepmatcher_textual_abt_buy':deepmatcher_textual_abt_buy,\n",
    "    #'deepmatcher_textual_company':deepmatcher_textual_company,  uses too much time\n",
    "    #'comperbench_abt_buy':comperbench_abt_buy,\n",
    "    #'comperbench_wdc_xlarge_shoes':comperbench_wdc_xlarge_shoes,   fails\n",
    "}\n",
    "\n",
    "dataset_small = {\n",
    "    #'deepmatcher_textual_abt_buy':deepmatcher_textual_abt_buy,\n",
    "    #'deepmatcher_structured_itunes_amazon': deepmatcher_structured_itunes_amazon,\n",
    "    #'deepmatcher_structured_amazon_google': deepmatcher_structured_amazon_google,\n",
    "    #'deepmatcher_structured_dblp_acm': deepmatcher_structured_dblp_acm,\n",
    "    'deepmatcher_structured_dblp_google_scholar': deepmatcher_structured_dblp_google_scholar,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 22, f1-score: 0.8300429184549357, latency [0.29906272888183594]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "n_initial = 8\n",
    "k = 1 # samples = n_initial + n_queries * (k * 4)\n",
    "n_samples = 2000 # vi kan bare ta høyt tall her og så korte ned når vi gjør transformer senere\n",
    "\n",
    "run_al_all(n_samples=100, all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
